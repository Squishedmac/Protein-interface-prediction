{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ce698",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch_lightning\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b2d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "from pytorch_lightning import Trainer\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from torch.optim import Adam\n",
    "from torch import optim as optim\n",
    "import random\n",
    "import math\n",
    "from torch_sparse import SparseTensor\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from transformers import AdamW\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch_geometric.nn import Sequential, TransformerConv,BatchNorm,Set2Set\n",
    "from torch.nn.functional import normalize\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve,average_precision_score,recall_score,precision_score,matthews_corrcoef\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv,DenseSAGEConv\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209a9e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data for interprotein  link prediction\n",
    "fullsamples=np.load('/workspace/file_name.npy')\n",
    "\n",
    "xyzl=[]\n",
    "xyz_outl = []\n",
    "input_edges_rec = []\n",
    "input_edges_lig = []\n",
    "sample_filel = []\n",
    "maked_inputl = []\n",
    "len_rec = []\n",
    "coord_all=[]\n",
    "edge_index_rec=[]\n",
    "edge_index_lig=[]\n",
    "one_hot=[]\n",
    "feat_in=[]\n",
    "def sigm(g):\n",
    "    return(1/(1+math.exp(-g/100)))\n",
    "for i in range(len(fullsamples)):\n",
    "    edgesrec = []\n",
    "    edgeslig = []\n",
    "#     if fullsamples[i]+'_' in samplesppi4:\n",
    "    try:\n",
    "        try:\n",
    "            datain= torch.load(os.path.join('/workspace/madhav/all_feat/ALL/'+str(fullsamples[i]).split('_')[0].upper()+'.'+str(fullsamples[i]).split('_')[1].split(':')[0]+'.'+str(fullsamples[i]).split('_')[1].split(':')[1]+'.'+'_input_feat.pt'))\n",
    "        except:\n",
    "            datain= torch.load(os.path.join('/workspace/madhav/all_feat/ALL/'+str(fullsamples[i]).split('_')[0].lower()+'.'+str(fullsamples[i]).split('_')[1].split(':')[0]+'.'+str(fullsamples[i]).split('_')[1].split(':')[1]+'.'+'_input_feat.pt')) \n",
    "        pssm = torch.load(os.path.join('/workspace/pssmdb5ppiprism',fullsamples[i]+'_pssm.pt'))\n",
    "        edgesrec = torch.load(os.path.join('/workspace/InputEdge_file_nameedge_rec', fullsamples[i]+'_edge_rec.pt'))\n",
    "        edgeslig = torch.load(os.path.join('/workspace/InputEdge_file_nameedge_lig', fullsamples[i]+'_edge_lig.pt'))\n",
    "        adjl = torch.load(os.path.join('/workspace/inputfeatdb5ppiprism',fullsamples[i]+'_adj_rec.pt')) \n",
    "        adjr = torch.load(os.path.join('/workspace/inputfeatdb5ppiprism',fullsamples[i]+'_adj_lig.pt')) \n",
    "        interface = torch.load(os.path.join('/workspace/ReadyToPair', fullsamples[i]+'_interface.pt'))\n",
    "    except:\n",
    "        continue\n",
    "    if not(datain.shape[0]==pssm.shape[0]==interface.shape[0] ) :# or  interface.sum()==0.:\n",
    "        continue\n",
    "    feat = torch.hstack((datain, pssm))\n",
    "    rcc=feat[:, 46].cpu()\n",
    "    unique, counts = np.unique(rcc, return_counts=True)\n",
    "    coun = dict(zip(unique, counts))\n",
    "    rec_c = coun[0.0]\n",
    "    receptor = feat[:rec_c, 3:]\n",
    "    ligand = feat[rec_c:, 3:]\n",
    "    coord=feat[:,:3]\n",
    "#     one_hot=feat[:,26:46,]\n",
    "    if receptor.shape[0]>999 or receptor.shape[0]<75 or ligand.shape[0]>999 or ligand.shape[0]<75:\n",
    "        continue\n",
    "#     receptor = receptor.expand(receptor.shape[0], receptor.shape[0],receptor.shape[1]).permute(2,1,0)\n",
    "#     ligand = ligand.expand(ligand.shape[0], ligand.shape[0],ligand.shape[1]).permute(2,1,0)\n",
    "#     print(i,ligand.shape)\n",
    "    len_rec.append(rec_c)\n",
    "    input_edges_rec.append(adjr)\n",
    "    input_edges_lig.append(adjl)\n",
    "    edge_index_rec.append(adjr.nonzero().t().contiguous())\n",
    "    edge_index_lig.append(adjl.nonzero().t().contiguous())\n",
    "#     print(feat[:,26:46,])\n",
    "    one_hot.append(feat[:,26:46,])\n",
    "    feat\n",
    "    for coor in coord:\n",
    "        coor[0]=sigm(coor[0])\n",
    "        coor[1]=sigm(coor[1])\n",
    "        coor[2]=sigm(coor[2])\n",
    "    new=torch.cat((feat[:,:26],feat[:,46:]),1)\n",
    "    feat_in.append(new)\n",
    "#     print(feat_in.shape)\n",
    "    new = new[:,3:]\n",
    "    xyzl.append(new)\n",
    "    coord_all.append(coord)\n",
    "    sample_filel.append(i)\n",
    "     #fullsamples.index(i))\n",
    "#     input_edges_rec.append(edgesrec)\n",
    "#     input_edges_lig.append(edgeslig)\n",
    "    xyz_outl.append(torch.load(os.path.join('/workspace/ReadyToPair', fullsamples[i]+'_interface.pt')))\n",
    "    print('done')\n",
    "    #     break\n",
    "    \n",
    "len(xyzl), len(xyz_outl), len(len_rec)#, len(input_edges_lig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da34abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feat_in[0].shape)\n",
    "print(new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c760e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(coord_all[2281])\n",
    "# torch.set_printoptions(threshold=10_000)\n",
    "# print(feat.shape)\n",
    "# print(feat)\n",
    "# # feat = feat[:,3:]\n",
    "# print(feat.shape)\n",
    "# print(feat)\n",
    "# # print(feat[:,26:46,].shape)\n",
    "# # print(xyzl[2281])\n",
    "# print(feat[:,:26],feat[:,46:])\n",
    "# print('=====================================')\n",
    "# print(feat[:,:23].shape,feat[:,43:].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90cc71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataL(pl.LightningDataModule):\n",
    "    def __init__(self, node,  xyz_out, len_rec,input_edges_lig,input_edges_rec,coord,edge_index_rec,edge_index_lig,fold,oh): #rec_edge, lig_edge,\n",
    "        super().__init__()\n",
    "        self.node = node\n",
    "        self.xyz_out = xyz_out\n",
    "        self.rec_edge = input_edges_rec\n",
    "        self.lig_edge = input_edges_lig\n",
    "        self.len_rec = len_rec\n",
    "        self.coord   =coord\n",
    "        self.edge_index_rec=edge_index_rec\n",
    "        self.edge_index_lig=edge_index_lig\n",
    "        self.fold=fold\n",
    "        self.one_hot=oh\n",
    "        self.setup()\n",
    "        \n",
    "    def setup(self, stage = None):\n",
    "        counto=0\n",
    "        together=[]\n",
    "        self.data= []\n",
    "        train_set=[]\n",
    "        test_set=[]\n",
    "        for i in range(len(self.node)):\n",
    "            self.data.append([\n",
    "                              self.node[i].float().clone().detach(),\n",
    "                              self.xyz_out[i].float().clone().detach(),\n",
    "                              self.coord[i].float().clone().detach(),\n",
    "                              self.lig_edge[i].float().clone().detach(),\n",
    "                              self.rec_edge[i].float().clone().detach(),\n",
    "                              self.edge_index_lig[i].float().clone().detach(),\n",
    "                              self.edge_index_rec[i].float().clone().detach(),\n",
    "                              self.len_rec[i],\n",
    "                              self.one_hot[i]])\n",
    "        \n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=11001)    \n",
    "        for tog in kf.split(self.data):\n",
    "            together=together+[tog]\n",
    "        ti,vi=together[self.fold]\n",
    "        self.tii, self.vii = ti.tolist(), vi.tolist()\n",
    "        for i in self.vii:\n",
    "            test_set.append(self.data[i])\n",
    "        for i in self.tii:\n",
    "            train_set.append(self.data[i])\n",
    "\n",
    "\n",
    "        self.train_set,self.val_set=train_set,test_set\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=1,num_workers=32)\n",
    "\n",
    "#     def val_dataloader(self):\n",
    "#         return DataLoader(self.val_set, batch_size=1,num_workers=32)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=1,num_workers=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a3b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Parameter\n",
    "\n",
    "\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.nn.inits import zeros\n",
    "\n",
    "class DenseGCNConv(torch.nn.Module):\n",
    "    r\"\"\"See :class:`torch_geometric.nn.conv.GCNConv`.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, improved=False, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.improved = improved\n",
    "\n",
    "        self.lin = Linear(in_channels, out_channels, bias=False,\n",
    "                          weight_initializer='glorot')\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        stdv = 1. / math.sqrt(self.out_channels)\n",
    "        self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None, add_loop=True):\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            x (Tensor): Node feature tensor :math:`\\mathbf{X} \\in \\mathbb{R}^{B\n",
    "                \\times N \\times F}`, with batch-size :math:`B`, (maximum)\n",
    "                number of nodes :math:`N` for each graph, and feature\n",
    "                dimension :math:`F`.\n",
    "            adj (Tensor): Adjacency tensor :math:`\\mathbf{A} \\in \\mathbb{R}^{B\n",
    "                \\times N \\times N}`. The adjacency tensor is broadcastable in\n",
    "                the batch dimension, resulting in a shared adjacency matrix for\n",
    "                the complete batch.\n",
    "            mask (BoolTensor, optional): Mask matrix\n",
    "                :math:`\\mathbf{M} \\in {\\{ 0, 1 \\}}^{B \\times N}` indicating\n",
    "                the valid nodes for each graph. (default: :obj:`None`)\n",
    "            add_loop (bool, optional): If set to :obj:`False`, the layer will\n",
    "                not automatically add self-loops to the adjacency matrices.\n",
    "                (default: :obj:`True`)\n",
    "        \"\"\"\n",
    "        x = x.unsqueeze(0) if x.dim() == 2 else x\n",
    "        adj = adj.unsqueeze(0) if adj.dim() == 2 else adj\n",
    "        B, N, _ = adj.size()\n",
    "\n",
    "        if add_loop:\n",
    "            adj = adj.clone()\n",
    "            idx = torch.arange(N, dtype=torch.long, device=adj.device)\n",
    "            adj[:, idx, idx] = 1 if not self.improved else 2\n",
    "\n",
    "        out = self.lin(x)\n",
    "        deg_inv_sqrt = adj.sum(dim=-1).clamp(min=1).pow(-0.5)\n",
    "\n",
    "        adj = deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2)\n",
    "        out = torch.matmul(adj, out)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias\n",
    "\n",
    "        if mask is not None:\n",
    "            out = out * mask.view(B, N, 1).to(x.dtype)\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4055de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.nn import DenseGCNConv,DenseGINConv,DenseGraphConv,DenseSAGEConv\n",
    "class NetR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = DenseGCNConv(128, 128) \n",
    "        self.l2 = DenseGCNConv(256, 256)\n",
    "        self.l3 = DenseGCNConv(128, 128)\n",
    "        self.l4 = DenseGCNConv(64, 64)\n",
    "        self.l5 = DenseGCNConv(1024, 1024)\n",
    "        self.l6 = DenseGCNConv(512, 512)\n",
    "        self.l7 = DenseGCNConv(256, 256)\n",
    "        self.l8 = DenseGCNConv(128, 128)\n",
    "        self.l9 = DenseGCNConv(64, 64)\n",
    "        self.attn1 = nn.MultiheadAttention(128, 4)\n",
    "        self.attn2 = nn.MultiheadAttention(256, 4)\n",
    "        self.attn3 = nn.MultiheadAttention(128, 4)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.sig =nn.Sigmoid()\n",
    "        embed_dim = 512\n",
    "        num_heads = 4\n",
    "        self.o0=nn.LayerNorm(128)\n",
    "        self.o1=nn.LayerNorm(256)\n",
    "        self.o2=nn.LayerNorm(128)\n",
    "        self.o3=nn.LayerNorm(64)\n",
    "        self.b0=nn.Bilinear(164,128,256)\n",
    "        self.b1=nn.Bilinear(256,128,64)\n",
    "\n",
    "        self.h0 = nn.Linear(164,128)\n",
    "#         self.h1 = nn.Linear(128,256)\n",
    "        self.h2 = nn.Linear(256,128)\n",
    "#         self.h3 = nn.Linear(128,64)\n",
    "\n",
    "#         self.h4 = nn.Linear(2048,1024)\n",
    "#         self.h5 = nn.Linear(1024,512)\n",
    "#         self.h6 = nn.Linear(512,256)\n",
    "#         self.h7 = nn.Linear(256,128)\n",
    "#         self.h8 = nn.Linear(128,64)\n",
    "        self.h9 = nn.Linear(64,64)\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.dropout = 0.25\n",
    "    def forward(self, x, adjacency):\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "\n",
    "        x1 =self.relu(self.h0(x))#64->100\n",
    "        x1 = self.o0(x1)\n",
    "        x1 = self.relu(self.l1( x1, adjacency)+x1) \n",
    "        x1 = F.dropout(x1, self.dropout, training=self.training)\n",
    "        x1,_= self.attn1(x1, x1 ,x1)\n",
    "        x1=x1.squeeze(0)\n",
    "        \n",
    "        x2 =self.relu(self.b0(x,x1))##100->380,200\n",
    "        x2 = self.o1(x2)\n",
    "        x2 = self.relu(self.l2( x2, adjacency)+x2)\n",
    "        x2= F.dropout(x2, self.dropout, training=self.training)\n",
    "        x2,_= self.attn2(x2, x2 ,x2)\n",
    "        x2=x2.squeeze(0)\n",
    "        \n",
    "        x3 =self.relu(self.h2(x2))\n",
    "        x3 = self.o2(x3)\n",
    "        x3 = self.relu(self.l3( x3, adjacency)+x3)\n",
    "        x3 = F.dropout(x3, self.dropout, training=self.training)\n",
    "        x3,_= self.attn3(x3, x3 ,x3)\n",
    "        x3=x3.squeeze(0)\n",
    "        \n",
    "        x4 =self.relu(self.b1(x2,x3))\n",
    "        x4 = self.o3(x4)\n",
    "        x4 = self.relu(self.l4( x4, adjacency)+x4)\n",
    "        x4 = F.dropout(x4, self.dropout, training=self.training)\n",
    "#         h4 =self.relu(self.h4(x4))\n",
    "\n",
    "#         x5 = self.relu(self.l5( h4, adjacency))\n",
    "#         x5,_= self.attn3(x5, x5 ,x5)\n",
    "\n",
    "#         x5 = F.layer_norm(x5,[x5.size()[-1]])\n",
    "#         x5 = F.dropout(x5, self.dropout, training=self.training)\n",
    "#         h5 =self.relu(self.h5(x5))\n",
    "\n",
    "#         x6 = self.relu(self.l6( h5, adjacency))\n",
    "#         x6,_= self.attn2(x6, x6 ,x6)\n",
    "#         x6 = F.layer_norm(x6,[x6.size()[-1]])\n",
    "#         x6 = F.dropout(x6, self.dropout, training=self.training)\n",
    "#         h6 =self.relu(self.h6(x6))\n",
    "#         x7 = self.relu(self.l7( h6, adjacency))\n",
    "#         x7,_= self.attn1(x7, x7 ,x7)\n",
    "#         x7 = F.layer_norm(x7,[x7.size()[-1]])\n",
    "#         x7 = F.dropout(x7, self.dropout, training=self.training)\n",
    "#         h7 =self.relu(self.h7(x7))\n",
    "#         x8 = self.relu(self.l8( h7, adjacency))\n",
    "#         x8 = F.layer_norm(x8,[x8.size()[-1]])\n",
    "#         x8 = F.dropout(x8, self.dropout, training=self.training)\n",
    "#         h8 =self.relu(self.h8(x8))\n",
    "#         x9 = self.relu(self.l9(h8, adjacency))\n",
    "#         x9 = F.layer_norm(x9,[x9.size()[-1]])\n",
    "#         x9 = F.dropout(x9, self.dropout, training=self.training)\n",
    "                \n",
    "\n",
    "        return x4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d5ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.nn import DenseGCNConv,DenseGINConv,DenseGraphConv,DenseSAGEConv\n",
    "class NetL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = DenseGCNConv(128, 128) \n",
    "        self.l2 = DenseGCNConv(256, 256)\n",
    "        self.l3 = DenseGCNConv(128, 128)\n",
    "        self.l4 = DenseGCNConv(64, 64)\n",
    "        self.l5 = DenseGCNConv(1024, 1024)\n",
    "        self.l6 = DenseGCNConv(512, 512)\n",
    "        self.l7 = DenseGCNConv(256, 256)\n",
    "        self.l8 = DenseGCNConv(128, 128)\n",
    "        self.l9 = DenseGCNConv(64, 64)\n",
    "        self.attn1 = nn.MultiheadAttention(128, 4)\n",
    "        self.attn2 = nn.MultiheadAttention(256, 4)\n",
    "        self.attn3 = nn.MultiheadAttention(128, 4)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.sig =nn.Sigmoid()\n",
    "        embed_dim = 512\n",
    "        num_heads = 4\n",
    "        self.o0=nn.LayerNorm(128)\n",
    "        self.o1=nn.LayerNorm(256)\n",
    "        self.o2=nn.LayerNorm(128)\n",
    "        self.o3=nn.LayerNorm(64)\n",
    "        self.b0=nn.Bilinear(164,128,256)\n",
    "        self.b1=nn.Bilinear(256,128,64)\n",
    "\n",
    "        self.h0 = nn.Linear(164,128)\n",
    "#         self.h1 = nn.Linear(128,256)\n",
    "        self.h2 = nn.Linear(256,128)\n",
    "#         self.h3 = nn.Linear(128,64)\n",
    "\n",
    "#         self.h4 = nn.Linear(2048,1024)\n",
    "#         self.h5 = nn.Linear(1024,512)\n",
    "#         self.h6 = nn.Linear(512,256)\n",
    "#         self.h7 = nn.Linear(256,128)\n",
    "#         self.h8 = nn.Linear(128,64)\n",
    "        self.h9 = nn.Linear(64,64)\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.dropout = 0.25\n",
    "    def forward(self, x, adjacency):\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "\n",
    "        x1 =self.relu(self.h0(x))#64->100\n",
    "        x1 = self.o0(x1)\n",
    "        x1 = self.relu(self.l1( x1, adjacency)+x1) \n",
    "        x1 = F.dropout(x1, self.dropout, training=self.training)\n",
    "        x1,_= self.attn1(x1, x1 ,x1)\n",
    "        x1=x1.squeeze(0)\n",
    "        \n",
    "        x2 =self.relu(self.b0(x,x1))##100->380,200\n",
    "        x2 = self.o1(x2)\n",
    "        x2 = self.relu(self.l2( x2, adjacency)+x2)\n",
    "        x2= F.dropout(x2, self.dropout, training=self.training)\n",
    "        x2,_= self.attn2(x2, x2 ,x2)\n",
    "        x2=x2.squeeze(0)\n",
    "        \n",
    "        x3 =self.relu(self.h2(x2))\n",
    "        x3 = self.o2(x3)\n",
    "        x3 = self.relu(self.l3( x3, adjacency)+x3)\n",
    "        x3 = F.dropout(x3, self.dropout, training=self.training)\n",
    "        x3,_= self.attn3(x3, x3 ,x3)\n",
    "        x3=x3.squeeze(0)\n",
    "        \n",
    "        x4 =self.relu(self.b1(x2,x3))\n",
    "        x4 = self.o3(x4)\n",
    "        x4 = self.relu(self.l4( x4, adjacency)+x4)\n",
    "        x4 = F.dropout(x4, self.dropout, training=self.training)\n",
    "#         h4 =self.relu(self.h4(x4))\n",
    "\n",
    "#         x5 = self.relu(self.l5( h4, adjacency))\n",
    "#         x5,_= self.attn3(x5, x5 ,x5)\n",
    "\n",
    "#         x5 = F.layer_norm(x5,[x5.size()[-1]])\n",
    "#         x5 = F.dropout(x5, self.dropout, training=self.training)\n",
    "#         h5 =self.relu(self.h5(x5))\n",
    "\n",
    "#         x6 = self.relu(self.l6( h5, adjacency))\n",
    "#         x6,_= self.attn2(x6, x6 ,x6)\n",
    "#         x6 = F.layer_norm(x6,[x6.size()[-1]])\n",
    "#         x6 = F.dropout(x6, self.dropout, training=self.training)\n",
    "#         h6 =self.relu(self.h6(x6))\n",
    "#         x7 = self.relu(self.l7( h6, adjacency))\n",
    "#         x7,_= self.attn1(x7, x7 ,x7)\n",
    "#         x7 = F.layer_norm(x7,[x7.size()[-1]])\n",
    "#         x7 = F.dropout(x7, self.dropout, training=self.training)\n",
    "#         h7 =self.relu(self.h7(x7))\n",
    "#         x8 = self.relu(self.l8( h7, adjacency))\n",
    "#         x8 = F.layer_norm(x8,[x8.size()[-1]])\n",
    "#         x8 = F.dropout(x8, self.dropout, training=self.training)\n",
    "#         h8 =self.relu(self.h8(x8))\n",
    "#         x9 = self.relu(self.l9(h8, adjacency))\n",
    "#         x9 = F.layer_norm(x9,[x9.size()[-1]])\n",
    "#         x9 = F.dropout(x9, self.dropout, training=self.training)\n",
    "                \n",
    "\n",
    "        return x4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fd9e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetCoord(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = DenseGCNConv(32, 32) \n",
    "        self.l2 = DenseGCNConv(64, 64)\n",
    "        self.l3 = DenseGCNConv(128, 128)\n",
    "        self.l4 = DenseGCNConv(64, 64)\n",
    "        self.l5 = DenseGCNConv(32, 32)\n",
    "        self.l6 = DenseGCNConv(64, 64)\n",
    "        self.l7 = DenseGCNConv(32, 32)\n",
    "        self.l8 = DenseGCNConv(128, 128)\n",
    "        self.l9 = DenseGCNConv(64, 64)\n",
    "        self.attn1 = nn.MultiheadAttention(32, 8)\n",
    "        self.attn2 = nn.MultiheadAttention(64, 8)\n",
    "        self.attn3 = nn.MultiheadAttention(128, 8)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        embed_dim = 512\n",
    "        num_heads = 4\n",
    "        self.h0 = nn.Linear(3,32)\n",
    "        self.h1 = nn.Linear(32,64)\n",
    "        self.h2 = nn.Linear(64,128)\n",
    "        self.h3 = nn.Linear(128,64)\n",
    "        self.h4 = nn.Linear(64,32)\n",
    "        self.h5 = nn.Linear(32,3)\n",
    "\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.dropout = (0.3)\n",
    "    def forward(self, x, adjacency):\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        h0 =self.relu(self.h0(x))#64->100\n",
    "        x1 = self.relu(self.l1( h0, adjacency)) \n",
    "        x1 = F.layer_norm(x1,[x1.size()[-1]])\n",
    "        x1 = F.dropout(x1, self.dropout, training=self.training)\n",
    "        h1 =self.relu(self.h1(x1))##100->380,200\n",
    "        x2 = self.relu(self.l2( h1, adjacency))\n",
    "        x2 = F.layer_norm(x2,[x2.size()[-1]])\n",
    "        x2= F.dropout(x2, self.dropout, training=self.training)\n",
    "        h2 =self.relu(self.h2(x2))\n",
    "        x3 = self.relu(self.l3( h2, adjacency))\n",
    "        x3 = F.layer_norm(x3,[x3.size()[-1]])\n",
    "        x3 = F.dropout(x3, self.dropout, training=self.training)\n",
    "        h3 =self.relu(self.h3(x3))\n",
    "        x4 = self.relu(self.l4( h3, adjacency))\n",
    "        x4 = F.layer_norm(x4,[x4.size()[-1]])\n",
    "        x4 = F.dropout(x4, self.dropout, training=self.training)\n",
    "        h4 =self.relu(self.h4(x4))\n",
    "\n",
    "        x5 = self.relu(self.l5( h4, adjacency))\n",
    "\n",
    "        x5 = F.layer_norm(x5,[x5.size()[-1]])\n",
    "        x5 = F.dropout(x5, self.dropout, training=self.training)\n",
    "#         x5 =self.relu(self.h5(x5))\n",
    "\n",
    "\n",
    "\n",
    "        return x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a9b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class GeneratorL(LightningModule):\n",
    "    def __init__(self):\n",
    "            super(GeneratorL, self).__init__()\n",
    "            self.Amean = []\n",
    "            self.Lmean = []\n",
    "            self.wholeAmean = []\n",
    "            self.wholeLmean = []\n",
    "            self.model= NetL() #Attention_UNET(44,1)\n",
    "            \n",
    "          #why are we using conv2d?                      \n",
    "\n",
    "    def forward(self, x, edge_rec):\n",
    "        return self.model( x, edge_rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f697ea87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class GeneratorR(LightningModule):\n",
    "    def __init__(self):\n",
    "            super(GeneratorR, self).__init__()\n",
    "            self.Amean = []\n",
    "            self.Lmean = []\n",
    "            self.wholeAmean = []\n",
    "            self.wholeLmean = []\n",
    "            self.model= NetR() #Attention_UNET(44,1)\n",
    "\n",
    "          #why are we using conv2d?                      \n",
    "\n",
    "    def forward(self, x, edge_rec):\n",
    "        return self.model( x, edge_rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cf484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorCoord(LightningModule):\n",
    "    def __init__(self):\n",
    "            super(GeneratorCoord, self).__init__()\n",
    "            self.Amean = []\n",
    "            self.Lmean = []\n",
    "            self.wholeAmean = []\n",
    "            self.wholeLmean = []\n",
    "            self.model= NetCoord() #Attention_UNET(44,1)\n",
    "\n",
    "          #why are we using conv2d?                      \n",
    "\n",
    "    def forward(self, x, edge_rec):\n",
    "        return self.model( x, edge_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinkPred(LightningModule):\n",
    "    def __init__(self):\n",
    "        super(LinkPred, self).__init__()\n",
    "        self.Amean = []\n",
    "        self.Lmean = []\n",
    "        self.wholeAmean = []\n",
    "        self.wholeLmean = []\n",
    "    \n",
    "        output_ch = 64\n",
    "        self.multihead_attn = nn.MultiheadAttention( output_ch, 4)\n",
    "\n",
    "        self.h_feats_dim = 96\n",
    "        self.att_mlp_Q = nn.Sequential(nn.Linear(self.h_feats_dim, self.h_feats_dim, bias=True),\\\n",
    "                                  nn.LeakyReLU())# get_non_lin(nonlin, leakyrelu_neg_slope),\n",
    "        self.att_mlp_K = nn.Sequential(nn.Linear(self.h_feats_dim, self.h_feats_dim, bias=True),\\\n",
    "                                  nn.LeakyReLU())#get_non_lin(nonlin, leakyrelu_neg_slope),\n",
    "        self.att_mlp_V = nn.Linear(self.h_feats_dim, self.h_feats_dim, bias=True)\n",
    "        self.cross_msgs = True\n",
    "        self.coordlayer=GeneratorCoord()\n",
    "        self.modelL=GeneratorL()\n",
    "        self.modelR=GeneratorR()\n",
    "        self.ls=nn.LSTM(20,60,num_layers=3,bias=True,bidirectional=True)\n",
    "        self.layer_2 = nn.Sequential(nn.Linear(self.h_feats_dim, 128), nn.LeakyReLU(), nn.Linear(128, 256),\\\n",
    "                    nn.LeakyReLU(), nn.Linear(256, 1))\n",
    "    \n",
    "\n",
    "    def forward(self, x,edge,no):\n",
    "        if no==1:\n",
    "            return self.modelR(x,edge)\n",
    "        else:\n",
    "            return self.modelL(x,edge)          \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x,  y,coord,r_edge,l_edge,edge_i_l,edge_i_r,rec_len,oh = batch ##x:1,L,44 y:1,L\n",
    "\n",
    "        l_edge=l_edge.squeeze(0)\n",
    "        r_edge=r_edge.squeeze(0)\n",
    "        receptor = x[0][:rec_len,:]\n",
    "        ligand  = x[0][rec_len:,:]\n",
    "        coord_rec=(coord.squeeze(0)[:rec_len,:])\n",
    "        coord_lig=(coord.squeeze(0)[rec_len:,:])\n",
    "        edge_i_r=edge_i_r.squeeze(0)\n",
    "        edge_i_l=edge_i_l.squeeze(0)\n",
    "        oh=oh.squeeze(0)\n",
    "        \n",
    "        output_rec,(hs_r,cs_r)=self.ls(oh[:rec_len,:].unsqueeze(0).float())\n",
    "        output_lig,(hs_l,cs_l)=self.ls(oh[rec_len:,:].unsqueeze(0).float())\n",
    "        output_rec=output_rec.squeeze(0) \n",
    "        output_lig=output_lig.squeeze(0)\n",
    "    \n",
    "        \n",
    "        outr_coord=self.coordlayer(coord_rec,r_edge)\n",
    "        receptor=torch.cat((receptor,output_rec),1)\n",
    "        \n",
    "        outr = self(receptor.float(),r_edge,1)#.permute(1,2,0)#[0] #L,L,64\n",
    "\n",
    "        outr, _ = self.multihead_attn(outr, outr, outr) #.to(device)\n",
    "        outr=torch.cat((outr_coord,outr),2)\n",
    "        \n",
    "        ligand=torch.cat((ligand,output_lig),1)\n",
    "        outl = self(ligand.float(),l_edge,0)#.permute(1,2,0)#[0] #L,L,64\n",
    "        outl_coord=self.coordlayer(coord_lig,l_edge)\n",
    "        \n",
    "        outl, _ = self.multihead_attn(outl, outl, outl) #.to(device)\n",
    "        outl=torch.cat((outl_coord,outl),2)  \n",
    "\n",
    "        assert torch.isfinite(outr).any()\n",
    "        assert torch.isfinite(outl).any()\n",
    "        \n",
    "        \n",
    "        rec, lig = self.cross_attention_layer(outr[0].to(device), outl[0].to(device))\n",
    "\n",
    "        com = torch.cat((rec, lig),0)\n",
    "#         com = com.transpose(1,0).unsqueeze(0).unsqueeze(-1)\n",
    "#         print('concat')\n",
    "        com = self.layer_2(com)\n",
    "        com=com.squeeze(-1)\n",
    "        out=com\n",
    "        \n",
    "#         print('layer2 over', com.get_device())\n",
    "#         out = torch.transpose(com, 1,0)\n",
    "#         out = com[0][0].transpose(1,0)\n",
    "        loss = 1.0*F.binary_cross_entropy_with_logits(out.float(), y[0].float(),\\\n",
    "                pos_weight=torch.FloatTensor([(y.size()[1]-float(y.sum()))*1.0/float(y.sum())]).type_as(out.float()))   \n",
    "        val = 0. # this is the value where you want the data to appear on the y-axis.\n",
    "        loss=loss.mean()\n",
    "\n",
    "\n",
    "        binoutput=torch.where(out>=0.5, 1., 0.)\n",
    "#         print('binoutput', binoutput.get_device())\n",
    "        \n",
    "#         print(binoutput.shape,receptor.shape, ligand.shape, 'binshape' )\n",
    "        one_index_out = torch.nonzero(binoutput).flatten().tolist()\n",
    "#         print('one_index_out')\n",
    "        one_index_y = torch.nonzero(y[0]).flatten().tolist()\n",
    "#         print('one_index_y')\n",
    "        accuaracy = len(list(set(one_index_out) & set(one_index_y)))/len(one_index_y)\n",
    "#         print('accuarcyok')\n",
    "        result_dict =  {'loss': loss, 'accuracy': accuaracy, 'in':out.unsqueeze(0), 'out':y}\n",
    "        \n",
    "# # #         loss=self.criterion(out[0].float(),y[0].float()) #+self.compute_body_intersection_loss(transformed, rec_coord)\n",
    "        return result_dict #loss\n",
    "    def train_epoch_end(self, outputs):\n",
    "            accuracy = []\n",
    "            loss = []\n",
    "\n",
    "            for i in outputs:\n",
    "                accuracy.append(i['accuracy'])\n",
    "                loss.append(i['loss'])\n",
    " \n",
    "            avg_accuracy= torch.mean(torch.tensor(accuracy).float())\n",
    "            avg_loss = torch.mean(torch.tensor(loss))\n",
    "\n",
    "            print('accuracy ',avg_accuracy,'loss',avg_loss)\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x,  y,coord,r_edge,l_edge,edge_i_l,edge_i_r,rec_len,oh = batch ##x:1,L,44 y:1,L\n",
    "\n",
    "        l_edge=l_edge.squeeze(0)\n",
    "        r_edge=r_edge.squeeze(0)\n",
    "        receptor = x[0][:rec_len,:]\n",
    "        ligand  = x[0][rec_len:,:]\n",
    "        coord_rec=(coord.squeeze(0)[:rec_len,:])\n",
    "        coord_lig=(coord.squeeze(0)[rec_len:,:])\n",
    "        edge_i_r=edge_i_r.squeeze(0)\n",
    "        edge_i_l=edge_i_l.squeeze(0)\n",
    "        oh=oh.squeeze(0)\n",
    "        \n",
    "        output_rec,(hs_r,cs_r)=self.ls(oh[:rec_len,:].unsqueeze(0).float())\n",
    "        output_lig,(hs_l,cs_l)=self.ls(oh[rec_len:,:].unsqueeze(0).float())\n",
    "        output_rec=output_rec.squeeze(0) \n",
    "        output_lig=output_lig.squeeze(0)\n",
    "    \n",
    "        \n",
    "        outr_coord=self.coordlayer(coord_rec,r_edge)\n",
    "        receptor=torch.cat((receptor,output_rec),1)\n",
    "        \n",
    "        outr = self(receptor.float(),r_edge,1)#.permute(1,2,0)#[0] #L,L,64\n",
    "\n",
    "        outr, _ = self.multihead_attn(outr, outr, outr) #.to(device)\n",
    "        outr=torch.cat((outr_coord,outr),2)\n",
    "        \n",
    "        ligand=torch.cat((ligand,output_lig),1)\n",
    "        outl = self(ligand.float(),l_edge,0)#.permute(1,2,0)#[0] #L,L,64\n",
    "        outl_coord=self.coordlayer(coord_lig,l_edge)\n",
    "        \n",
    "        outl, _ = self.multihead_attn(outl, outl, outl) #.to(device)\n",
    "        outl=torch.cat((outl_coord,outl),2)  \n",
    "\n",
    "        assert torch.isfinite(outr).any()\n",
    "        assert torch.isfinite(outl).any()\n",
    "        \n",
    "        \n",
    "        rec, lig = self.cross_attention_layer(outr[0].to(device), outl[0].to(device))\n",
    "\n",
    "        com = torch.cat((rec, lig),0)\n",
    "        com = self.layer_2(com)\n",
    "        com=com.squeeze(-1)\n",
    "        out=com\n",
    "        \n",
    "\n",
    "        loss = 1.0*F.binary_cross_entropy_with_logits(out.float(), y[0].float(),\\\n",
    "        pos_weight=torch.FloatTensor([(y.size()[1]-float(y.sum()))*1.0/float(y.sum())]).type_as(out.float()))    #.unsqueeze(0)\n",
    "        loss= loss.mean()\n",
    "        binoutput=torch.where(out>=0.5, 1., 0.)\n",
    "\n",
    "        cpuout = binoutput.flatten().cpu().detach().numpy()\n",
    "        cpuy = y.flatten().cpu().detach().numpy()\n",
    "        auc= roc_auc_score(cpuy, cpuout)\n",
    "#         accuracy = accuracy_score(cpuy, cpuout)\n",
    "        F1_score = f1_score(cpuy, cpuout)\n",
    "        recall= recall_score(cpuy, cpuout) #binoutput) #\n",
    "        precision= precision_score(cpuy, cpuout)\n",
    "        mcc= matthews_corrcoef(cpuy, cpuout)\n",
    "        aucpr=average_precision_score(cpuy,cpuout)\n",
    "\n",
    "        return { 'mcc': mcc,'Precision':precision, 'Recall':recall ,'F1_score':F1_score,'auroc':auc,'auc pr':aucpr} #'loss':loss,\n",
    "        \n",
    "    def test_epoch_end(self, outputs):\n",
    "        accuracy = []\n",
    "        loss = []\n",
    "        Mcc = []\n",
    "        Precision = []\n",
    "        Recall =[]\n",
    "        F1_score = []\n",
    "        auroc = []\n",
    "        aucpr=[]\n",
    "        for i in outputs:\n",
    "            Mcc.append(i['mcc'])\n",
    "            Precision.append(i['Precision'])\n",
    "            Recall.append(i['Recall'])\n",
    "            F1_score.append(i['F1_score'])\n",
    "            auroc.append(i['auroc'])\n",
    "            aucpr.append(i['auc pr'])\n",
    "        avg_accuracy= torch.mean(torch.tensor(accuracy).float())\n",
    "        avg_mcc = torch.mean(torch.tensor(Mcc).float())\n",
    "        avg_Precision = torch.mean(torch.tensor(Precision).float())\n",
    "        avg_Recall = torch.mean(torch.tensor(Recall).float())\n",
    "        avg_F1_score = torch.mean(torch.tensor(F1_score).float())\n",
    "        avg_auroc = torch.mean(torch.tensor(auroc).float())\n",
    "        avg_aucpr = torch.mean(torch.tensor(aucpr).float())\n",
    "\n",
    "        print( 'MCC: ',avg_mcc, 'P: ',avg_Precision,'R: ',avg_Recall,\\\n",
    "             'F1: ', avg_F1_score, 'AUROC: ',avg_auroc, 'AUCPR:',avg_aucpr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def compute_cross_attention(self, queries, keys, values, mask, cross_msgs):\n",
    "\n",
    "        if not self.cross_msgs:\n",
    "            return queries * 0.\n",
    "        mask = mask.to(device)\n",
    "        a = mask * torch.mm(queries, torch.transpose(keys, 1, 0)) - 1000. * (1. - mask)\n",
    "        a_x = torch.softmax(a, dim=1)  # i->j, NxM, a_x.sum(dim=1) = torch.ones(N)\n",
    "        attention_x = torch.mm(a_x, values)  # (N,d)\n",
    "        return attention_x\n",
    "\n",
    "\n",
    "\n",
    "    def get_mask(self, ligand_batch_num_nodes, receptor_batch_num_nodes):\n",
    "        rows = ligand_batch_num_nodes# sum()\n",
    "        cols = receptor_batch_num_nodes #sum()\n",
    "        mask = torch.ones(rows, cols)#.to(device)\n",
    "        return mask\n",
    "    def cross_attention_layer(self, rec_feat, lig_feat):\n",
    "#         before = torch.cat((rec_feat, lig_feat), 0)\n",
    "        \n",
    "        mask = self.get_mask( lig_feat.shape[0], rec_feat.shape[0])\n",
    "        cross_ligand = self.compute_cross_attention(self.att_mlp_Q(lig_feat),\n",
    "                                self.att_mlp_K(rec_feat),\n",
    "                                self.att_mlp_V(rec_feat),\n",
    "                                mask,\n",
    "                                self.cross_msgs)\n",
    "        cross_receptor = self.compute_cross_attention(self.att_mlp_Q(rec_feat),\n",
    "                                self.att_mlp_K(lig_feat),\n",
    "                                self.att_mlp_V(lig_feat),\n",
    "                                mask.transpose(0,1),\n",
    "                                self.cross_msgs)\n",
    "        cross_receptor += rec_feat\n",
    "        cross_ligand += lig_feat\n",
    "        \n",
    "        \n",
    "        return cross_receptor, cross_ligand  #combine\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        self.Amean = []\n",
    "        self.Lmean = []\n",
    "        \n",
    "        for i in outputs:\n",
    "            self.Amean.append(i['accuracy'])\n",
    "            self.Lmean.append(i['loss'])\n",
    "        self.wholeAmean.append(torch.mean(torch.tensor(self.Amean)))\n",
    "        self.wholeLmean.append(torch.mean(torch.tensor(self.Lmean)))\n",
    "        print(self.wholeLmean[-1])\n",
    "        self.logger.experiment.add_scalar('loss',torch.mean(torch.tensor(self.Amean)))\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "#         optimizer = optim.Adam(self.parameters(), lr=0.0005 , betas=(0.1, 0.999)) #self.lr\n",
    "        optimizer =  optim.RAdam(self.parameters(), lr=0.00005)\n",
    "        return optimizer\n",
    "\n",
    "modelpred = LinkPred()#.to(device) avg_pos_wt\n",
    "\n",
    "\n",
    "# logger = TensorBoardLogger(\"tb_logs\", name=\"model\")\n",
    "# trainer = Trainer(max_epochs=250,gpus=[2])\n",
    "# trainer.fit(modelpred,dataobjl)\n",
    "# trainer.save_checkpoint(\"linkpred_250_multi.ckpt\")\n",
    "# trainer.test(modelpred, dataobjl) \n",
    "# modelpred    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13a37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataobjl = ProteinDataL( xyzl,  xyz_outl, len_rec,input_edges_lig,input_edges_rec,coord_all,edge_index_rec,edge_index_lig,0,one_hot)#.to(device)  #edge_list, input_edges_rec, input_edges_lig,\n",
    "dataobjl.setup()\n",
    "trainer=Trainer(gpus=[1],max_epochs=3)\n",
    "trainer.fit(modelpred,dataobjl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc617b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(modelpred,dataobjl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataobjl = ProteinDataL( xyzl,  xyz_outl, len_rec,input_edges_lig,input_edges_rec,coord_all,edge_index_rec,edge_index_lig,0)#.to(device)  #edge_list, input_edges_rec, input_edges_lig,\n",
    "dataobjl.setup()\n",
    "trainer=Trainer(gpus=[1],max_epochs=100)\n",
    "trainer.fit(modelpred,dataobjl)\n",
    "trainer.test(modelpred,dataobjl)\n",
    "trainer.save_checkpoint(\"kfoldboii1.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca2bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataobjl = ProteinDataL( xyzl,  xyz_outl, len_rec,input_edges_lig,input_edges_rec,coord_all,edge_index_rec,edge_index_lig,1)#.to(device)  #edge_list, input_edges_rec, input_edges_lig,\n",
    "dataobjl.setup()\n",
    "trainer=Trainer(gpus=[1],max_epochs=100)\n",
    "trainer.fit(modelpred,dataobjl)\n",
    "trainer.test(modelpred,dataobjl)\n",
    "trainer.save_checkpoint(\"kfoldboii2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b58dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataobjl = ProteinDataL( xyzl,  xyz_outl, len_rec,input_edges_lig,input_edges_rec,coord_all,edge_index_rec,edge_index_lig,2)#.to(device)  #edge_list, input_edges_rec, input_edges_lig,\n",
    "dataobjl.setup()\n",
    "trainer=Trainer(gpus=[1],max_epochs=100)\n",
    "trainer.fit(modelpred,dataobjl)\n",
    "trainer.test(modelpred,dataobjl)\n",
    "trainer.save_checkpoint(\"kfoldboii3.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b61c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataobjl = ProteinDataL( xyzl,  xyz_outl, len_rec,input_edges_lig,input_edges_rec,coord_all,edge_index_rec,edge_index_lig,3)#.to(device)  #edge_list, input_edges_rec, input_edges_lig,\n",
    "dataobjl.setup()\n",
    "trainer=Trainer(gpus=[1],max_epochs=100)\n",
    "trainer.fit(modelpred,dataobjl)\n",
    "trainer.test(modelpred,dataobjl)\n",
    "trainer.save_checkpoint(\"kfoldboii4.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff386ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataobjl = ProteinDataL( xyzl,  xyz_outl, len_rec,input_edges_lig,input_edges_rec,coord_all,edge_index_rec,edge_index_lig,4)#.to(device)  #edge_list, input_edges_rec, input_edges_lig,\n",
    "dataobjl.setup()\n",
    "trainer=Trainer(gpus=[1],max_epochs=100)\n",
    "trainer.fit(modelpred,dataobjl)\n",
    "trainer.test(modelpred,dataobjl)\n",
    "trainer.save_checkpoint(\"kfoldboii5.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f9c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb068b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epipred test with no rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916958e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullsamples=np.load('/workspace/testEpi.npy')\n",
    "\n",
    "xyzl=[]\n",
    "xyz_outl = []\n",
    "input_edges_rec = []\n",
    "input_edges_lig = []\n",
    "sample_filel = []\n",
    "maked_inputl = []\n",
    "len_rec = []\n",
    "coord_all=[]\n",
    "edge_index_rec=[]\n",
    "edge_index_lig=[]\n",
    "sample_file=[]\n",
    "def sigm(g):\n",
    "    return(1/(1+math.exp(-g/100)))\n",
    "for i in range(len(fullsamples)):\n",
    "    \n",
    "    edgesrec = []\n",
    "    edgeslig = []\n",
    "#     if fullsamples[i]+'_' in samplesppi4:\n",
    "    try:\n",
    "        datain = torch.load(os.path.join('/workspace/EpipredFeat',fullsamples[i]+'_input_feat.pt'))\n",
    "        pssm = torch.load(os.path.join('/workspace/EpipredFeat',fullsamples[i]+'_pssm.pt'))\n",
    "        edgesrec = torch.load(os.path.join('/workspace/EpipredFeat', fullsamples[i]+'_edge_rec.pt'))\n",
    "        edgeslig = torch.load(os.path.join('/workspace/EpipredFeat', fullsamples[i]+'_edge_lig.pt'))\n",
    "        adjl = torch.load(os.path.join('/workspace/EpipredFeat',fullsamples[i]+'_adj_rec.pt')) \n",
    "        adjr = torch.load(os.path.join('/workspace/EpipredFeat',fullsamples[i]+'_adj_lig.pt')) \n",
    "        interface = torch.load(os.path.join('/workspace/EpipredFeat', fullsamples[i]+'_interface.pt'))\n",
    "    except:\n",
    "        continue\n",
    "    if not(datain.shape[0]==pssm.shape[0]==interface.shape[0] ) :# or  interface.sum()==0.:\n",
    "        continue\n",
    "    feat = torch.hstack((datain, pssm))\n",
    "    rcc=feat[:, 46].cpu()\n",
    "    unique, counts = np.unique(rcc, return_counts=True)\n",
    "    coun = dict(zip(unique, counts))\n",
    "    rec_c = coun[0.0]\n",
    "    receptor = feat[:rec_c, 3:]\n",
    "    ligand = feat[rec_c:, 3:]\n",
    "    coord=feat[:,:3]\n",
    "    if receptor.shape[0]>999 or receptor.shape[0]<75 or ligand.shape[0]>999 or ligand.shape[0]<75:\n",
    "        continue\n",
    "#     receptor = receptor.expand(receptor.shape[0], receptor.shape[0],receptor.shape[1]).permute(2,1,0)\n",
    "#     ligand = ligand.expand(ligand.shape[0], ligand.shape[0],ligand.shape[1]).permute(2,1,0)\n",
    "#     print(i,ligand.shape)\n",
    "    len_rec.append(rec_c)\n",
    "    input_edges_rec.append(adjr)\n",
    "    input_edges_lig.append(adjl)\n",
    "    edge_index_rec.append(adjr.nonzero().t().contiguous())\n",
    "    edge_index_lig.append(adjl.nonzero().t().contiguous())\n",
    "    for coor in coord:\n",
    "        coor[0]=sigm(coor[0])\n",
    "        coor[1]=sigm(coor[1])\n",
    "        coor[2]=sigm(coor[2])\n",
    "\n",
    "#     x1,x2,x3 = torch.from_numpy(np.random.uniform(3.14/12, 3.14, 3))\n",
    "#     cos1=torch.cos(x1)\n",
    "#     cos2=torch.cos(x2)\n",
    "#     cos3=torch.cos(x3)\n",
    "#     sin1=torch.sin(x1)\n",
    "#     sin2=torch.sin(x2)\n",
    "#     sin3=torch.sin(x3)\n",
    "#     RMatrix=torch.tensor([[cos1*cos2*cos3-sin1*sin3,cos3*cos2*sin1+sin3+cos1,-cos3*sin2 ],\\\n",
    "#                             [-sin3*cos2*cos1-cos3*sin1, -sin3*cos2*sin1+cos3*cos1, sin3*sin2],\\\n",
    "#                             [sin2*cos1,sin2*sin1,cos2]])\n",
    "\n",
    "#     ligcoord=  ((RMatrix @ torch.tensor(coord[rec_c:,]).double().T)).T\n",
    "#     reccoord=coord[:rec_c,:]\n",
    "\n",
    "#     coord=torch.cat((ligcoord,reccoord),0)\n",
    "    feat = feat[:,3:]\n",
    "    xyzl.append(feat)\n",
    "    coord_all.append(coord)\n",
    "    sample_filel.append(i)#fullsamples.index(i))\n",
    "#     input_edges_rec.append(edgesrec)\n",
    "#     input_edges_lig.append(edgeslig)\n",
    "    xyz_outl.append(torch.load(os.path.join('/workspace/EpipredFeat', fullsamples[i]+'_interface.pt')))\n",
    "    sample_file.append((fullsamples[i]+'1',fullsamples[i]+'2'))\n",
    "\n",
    "    #     break\n",
    "    \n",
    "len(xyzl), len(xyz_outl), len(len_rec)#, len(input_edges_lig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99c5bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataL(pl.LightningDataModule):\n",
    "    def __init__(self, node,  xyz_out, len_rec,input_edges_lig,input_edges_rec,coord,edge_index_rec,edge_index_lig,fold): #rec_edge, lig_edge,\n",
    "        super().__init__()\n",
    "        self.node = node\n",
    "        self.xyz_out = xyz_out\n",
    "        self.rec_edge = input_edges_rec\n",
    "        self.lig_edge = input_edges_lig\n",
    "        self.len_rec = len_rec\n",
    "        self.coord   =coord\n",
    "        self.edge_index_rec=edge_index_rec\n",
    "        self.edge_index_lig=edge_index_lig\n",
    "        self.fold=fold\n",
    "        self.setup()\n",
    "        \n",
    "    def setup(self, stage = None):\n",
    "        counto=0\n",
    "        together=[]\n",
    "        self.data= []\n",
    "        train_set=[]\n",
    "        test_set=[]\n",
    "        for i in range(len(self.node)):\n",
    "            self.data.append([\n",
    "                              self.node[i].float().clone().detach(),\n",
    "                              self.xyz_out[i].float().clone().detach(),\n",
    "                              self.coord[i].float().clone().detach(),\n",
    "                              self.lig_edge[i].float().clone().detach(),\n",
    "                              self.rec_edge[i].float().clone().detach(),\n",
    "                              self.edge_index_lig[i].float().clone().detach(),\n",
    "                              self.edge_index_rec[i].float().clone().detach(),\n",
    "                              self.len_rec[i]])\n",
    "        \n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=11001)    \n",
    "        for tog in kf.split(self.data):\n",
    "            together=together+[tog]\n",
    "        ti,vi=together[self.fold]\n",
    "        self.tii, self.vii = ti.tolist(), vi.tolist()\n",
    "        for i in self.vii:\n",
    "            test_set.append(self.data[i])\n",
    "        for i in self.tii:\n",
    "            train_set.append(self.data[i])\n",
    "\n",
    "\n",
    "        self.train_set,self.val_set=train_set,test_set\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=1,num_workers=32)\n",
    "\n",
    "#     def val_dataloader(self):\n",
    "#         return DataLoader(self.val_set, batch_size=1,num_workers=32)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=1,num_workers=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd86e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataobjl = ProteinDataL( xyzl,  xyz_outl, len_rec,input_edges_lig,input_edges_rec,coord_all,edge_index_rec,edge_index_lig,4)#.to(device)  #edge_list, input_edges_rec, input_edges_lig,\n",
    "dataobjl.setup()\n",
    "trainer=Trainer(gpus=[3],max_epochs=10)\n",
    "modelpres=LinkPred().load_from_checkpoint('kfoldboii_trial1.ckpt')\n",
    "# trainer.fit(modelpres,dataobjl)\n",
    "trainer.test(modelpres,dataobjl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d429efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epipred  with rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e098e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullsamples=np.load('/workspace/testEpi.npy')\n",
    "\n",
    "xyzl=[]\n",
    "xyz_outl = []\n",
    "input_edges_rec = []\n",
    "input_edges_lig = []\n",
    "sample_filel = []\n",
    "maked_inputl = []\n",
    "len_rec = []\n",
    "coord_all=[]\n",
    "edge_index_rec=[]\n",
    "edge_index_lig=[]\n",
    "sample_file=[]\n",
    "def sigm(g):\n",
    "    return(1/(1+math.exp(-g/100)))\n",
    "for i in range(len(fullsamples)):\n",
    "    edgesrec = []\n",
    "    edgeslig = []\n",
    "#     if fullsamples[i]+'_' in samplesppi4:\n",
    "    try:\n",
    "        datain = torch.load(os.path.join('/workspace/EpipredFeat',fullsamples[i]+'_input_feat.pt'))\n",
    "        pssm = torch.load(os.path.join('/workspace/EpipredFeat',fullsamples[i]+'_pssm.pt'))\n",
    "        edgesrec = torch.load(os.path.join('/workspace/EpipredFeat', fullsamples[i]+'_edge_rec.pt'))\n",
    "        edgeslig = torch.load(os.path.join('/workspace/EpipredFeat', fullsamples[i]+'_edge_lig.pt'))\n",
    "        adjl = torch.load(os.path.join('/workspace/EpipredFeat',fullsamples[i]+'_adj_rec.pt')) \n",
    "        adjr = torch.load(os.path.join('/workspace/EpipredFeat',fullsamples[i]+'_adj_lig.pt')) \n",
    "        interface = torch.load(os.path.join('/workspace/EpipredFeat', fullsamples[i]+'_interface.pt'))\n",
    "    except:\n",
    "        continue\n",
    "    if not(datain.shape[0]==pssm.shape[0]==interface.shape[0] ) :# or  interface.sum()==0.:\n",
    "        continue\n",
    "    feat = torch.hstack((datain, pssm))\n",
    "    rcc=feat[:, 46].cpu()\n",
    "    unique, counts = np.unique(rcc, return_counts=True)\n",
    "    coun = dict(zip(unique, counts))\n",
    "    rec_c = coun[0.0]\n",
    "    receptor = feat[:rec_c, 3:]\n",
    "    ligand = feat[rec_c:, 3:]\n",
    "    coord=feat[:,:3]\n",
    "    if receptor.shape[0]>999 or receptor.shape[0]<75 or ligand.shape[0]>999 or ligand.shape[0]<75:\n",
    "        continue\n",
    "#     receptor = receptor.expand(receptor.shape[0], receptor.shape[0],receptor.shape[1]).permute(2,1,0)\n",
    "#     ligand = ligand.expand(ligand.shape[0], ligand.shape[0],ligand.shape[1]).permute(2,1,0)\n",
    "#     print(i,ligand.shape)\n",
    "    len_rec.append(rec_c)\n",
    "    input_edges_rec.append(adjr)\n",
    "    input_edges_lig.append(adjl)\n",
    "    edge_index_rec.append(adjr.nonzero().t().contiguous())\n",
    "    edge_index_lig.append(adjl.nonzero().t().contiguous())\n",
    "    for coor in coord:\n",
    "        coor[0]=sigm(coor[0])\n",
    "        coor[1]=sigm(coor[1])\n",
    "        coor[2]=sigm(coor[2])\n",
    "\n",
    "    x1,x2,x3 = torch.from_numpy(np.random.uniform(3.14/12, 3.14, 3))\n",
    "    cos1=torch.cos(x1)\n",
    "    cos2=torch.cos(x2)\n",
    "    cos3=torch.cos(x3)\n",
    "    sin1=torch.sin(x1)\n",
    "    sin2=torch.sin(x2)\n",
    "    sin3=torch.sin(x3)\n",
    "    RMatrix=torch.tensor([[cos1*cos2*cos3-sin1*sin3,cos3*cos2*sin1+sin3+cos1,-cos3*sin2 ],\\\n",
    "                            [-sin3*cos2*cos1-cos3*sin1, -sin3*cos2*sin1+cos3*cos1, sin3*sin2],\\\n",
    "                            [sin2*cos1,sin2*sin1,cos2]])\n",
    "\n",
    "    ligcoord=  ((RMatrix @ torch.tensor(coord[rec_c:,]).double().T)).T\n",
    "    reccoord=coord[:rec_c,:]\n",
    "\n",
    "    coord=torch.cat((ligcoord,reccoord),0)\n",
    "    feat = feat[:,3:]\n",
    "    xyzl.append(feat)\n",
    "    coord_all.append(coord)\n",
    "    sample_filel.append(i)#fullsamples.index(i))\n",
    "#     input_edges_rec.append(edgesrec)\n",
    "#     input_edges_lig.append(edgeslig)\n",
    "    xyz_outl.append(torch.load(os.path.join('/workspace/EpipredFeat', fullsamples[i]+'_interface.pt')))\n",
    "    sample_file.append((fullsamples[i]+'1',fullsamples[i]+'2'))\n",
    "\n",
    "    #     break\n",
    "    \n",
    "len(xyzl), len(xyz_outl), len(len_rec)#, len(input_edges_lig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0a19f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataobjl = ProteinDataL( xyzl,  xyz_outl, len_rec,input_edges_lig,input_edges_rec,coord_all,edge_index_rec,edge_index_lig,4)#.to(device)  #edge_list, input_edges_rec, input_edges_lig,\n",
    "dataobjl.setup()\n",
    "trainer=Trainer(gpus=[1],max_epochs=10)\n",
    "modelpres=LinkPred().load_from_checkpoint('kfoldboii_trial1.ckpt')\n",
    "# trainer.fit(modelpres,dataobjl)\n",
    "trainer.test(modelpres,dataobjl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5029f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#db5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12b5812",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullsamples=np.load('/workspace/db5samplelist.npy')\n",
    "\n",
    "xyzl=[]\n",
    "xyz_outl = []\n",
    "input_edges_rec = []\n",
    "input_edges_lig = []\n",
    "sample_filel = []\n",
    "maked_inputl = []\n",
    "len_rec = []\n",
    "coord_all=[]\n",
    "edge_index_rec=[]\n",
    "edge_index_lig=[]\n",
    "def sigm(g):\n",
    "    return(1/(1+math.exp(-g/100)))\n",
    "for i in range(len(fullsamples)):\n",
    "    edgesrec = []\n",
    "    edgeslig = []\n",
    "#     if fullsamples[i]+'_' in samplesppi4:\n",
    "    try:\n",
    "        try:\n",
    "            datain= torch.load(os.path.join('/workspace/madhav/all_feat/ALL/'+str(fullsamples[i]).split('_')[0].upper()+'.'+str(fullsamples[i]).split('_')[1].split(':')[0]+'.'+str(fullsamples[i]).split('_')[1].split(':')[1]+'.'+'_input_feat.pt'))\n",
    "        except:\n",
    "            datain= torch.load(os.path.join('/workspace/madhav/all_feat/ALL/'+str(fullsamples[i]).split('_')[0].lower()+'.'+str(fullsamples[i]).split('_')[1].split(':')[0]+'.'+str(fullsamples[i]).split('_')[1].split(':')[1]+'.'+'_input_feat.pt')) \n",
    "        pssm = torch.load(os.path.join('/workspace/pssmdb5ppiprism',fullsamples[i]+'_pssm.pt'))\n",
    "        edgesrec = torch.load(os.path.join('/workspace/InputEdge_file_nameedge_rec', fullsamples[i]+'_edge_rec.pt'))\n",
    "        edgeslig = torch.load(os.path.join('/workspace/InputEdge_file_nameedge_lig', fullsamples[i]+'_edge_lig.pt'))\n",
    "        adjl = torch.load(os.path.join('/workspace/inputfeatdb5ppiprism',fullsamples[i]+'_adj_rec.pt')) \n",
    "        adjr = torch.load(os.path.join('/workspace/inputfeatdb5ppiprism',fullsamples[i]+'_adj_lig.pt')) \n",
    "        interface = torch.load(os.path.join('/workspace/ReadyToPair', fullsamples[i]+'_interface.pt'))\n",
    "    except:\n",
    "        continue\n",
    "    if not(datain.shape[0]==pssm.shape[0]==interface.shape[0] ) :# or  interface.sum()==0.:\n",
    "        continue\n",
    "    feat = torch.hstack((datain, pssm))\n",
    "    rcc=feat[:, 46].cpu()\n",
    "    unique, counts = np.unique(rcc, return_counts=True)\n",
    "    coun = dict(zip(unique, counts))\n",
    "    rec_c = coun[0.0]\n",
    "    receptor = feat[:rec_c, 3:]\n",
    "    ligand = feat[rec_c:, 3:]\n",
    "    coord=feat[:,:3]\n",
    "    if receptor.shape[0]>999 or receptor.shape[0]<75 or ligand.shape[0]>999 or ligand.shape[0]<75:\n",
    "        continue\n",
    "#     receptor = receptor.expand(receptor.shape[0], receptor.shape[0],receptor.shape[1]).permute(2,1,0)\n",
    "#     ligand = ligand.expand(ligand.shape[0], ligand.shape[0],ligand.shape[1]).permute(2,1,0)\n",
    "#     print(i,ligand.shape)\n",
    "    len_rec.append(rec_c)\n",
    "    input_edges_rec.append(adjr)\n",
    "    input_edges_lig.append(adjl)\n",
    "    edge_index_rec.append(adjr.nonzero().t().contiguous())\n",
    "    edge_index_lig.append(adjl.nonzero().t().contiguous())\n",
    "    for coor in coord:\n",
    "        coor[0]=sigm(coor[0])\n",
    "        coor[1]=sigm(coor[1])\n",
    "        coor[2]=sigm(coor[2])\n",
    "\n",
    "\n",
    "    feat = feat[:,3:]\n",
    "    xyzl.append(feat)\n",
    "    coord_all.append(coord)\n",
    "    sample_filel.append(i)#fullsamples.index(i))\n",
    "#     input_edges_rec.append(edgesrec)\n",
    "#     input_edges_lig.append(edgeslig)\n",
    "    xyz_outl.append(torch.load(os.path.join('/workspace/ReadyToPair', fullsamples[i]+'_interface.pt')))\n",
    "\n",
    "    #     break\n",
    "    \n",
    "len(xyzl), len(xyz_outl), len(len_rec)#, len(input_edges_lig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2576c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataobjl = ProteinDataL( xyzl,  xyz_outl, len_rec,input_edges_lig,input_edges_rec,coord_all,edge_index_rec,edge_index_lig,4)#.to(device)  #edge_list, input_edges_rec, input_edges_lig,\n",
    "dataobjl.setup()\n",
    "trainer=Trainer(gpus=[1],max_epochs=10)\n",
    "modelpres=LinkPred().load_from_checkpoint('kfoldboii_trial1.ckpt')\n",
    "# trainer.fit(modelpres,dataobjl)\n",
    "trainer.test(modelpres,dataobjl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9239a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINIG ON EPIPRED FOR 3 EPOCHS 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullsamples=np.load('/workspace/testEpi.npy')\n",
    "\n",
    "xyzl=[]\n",
    "xyz_outl = []\n",
    "input_edges_rec = []\n",
    "input_edges_lig = []\n",
    "sample_filel = []\n",
    "maked_inputl = []\n",
    "len_rec = []\n",
    "coord_all=[]\n",
    "edge_index_rec=[]\n",
    "edge_index_lig=[]\n",
    "sample_file=[]\n",
    "def sigm(g):\n",
    "    return(1/(1+math.exp(-g/100)))\n",
    "for i in range(len(fullsamples)):\n",
    "    edgesrec = []\n",
    "    edgeslig = []\n",
    "#     if fullsamples[i]+'_' in samplesppi4:\n",
    "    try:\n",
    "        datain = torch.load(os.path.join('/workspace/EpipredFeat',fullsamples[i]+'_input_feat.pt'))\n",
    "        pssm = torch.load(os.path.join('/workspace/EpipredFeat',fullsamples[i]+'_pssm.pt'))\n",
    "        edgesrec = torch.load(os.path.join('/workspace/EpipredFeat', fullsamples[i]+'_edge_rec.pt'))\n",
    "        edgeslig = torch.load(os.path.join('/workspace/EpipredFeat', fullsamples[i]+'_edge_lig.pt'))\n",
    "        adjl = torch.load(os.path.join('/workspace/EpipredFeat',fullsamples[i]+'_adj_rec.pt')) \n",
    "        adjr = torch.load(os.path.join('/workspace/EpipredFeat',fullsamples[i]+'_adj_lig.pt')) \n",
    "        interface = torch.load(os.path.join('/workspace/EpipredFeat', fullsamples[i]+'_interface.pt'))\n",
    "    except:\n",
    "        continue\n",
    "    if not(datain.shape[0]==pssm.shape[0]==interface.shape[0] ) :# or  interface.sum()==0.:\n",
    "        continue\n",
    "    feat = torch.hstack((datain, pssm))\n",
    "    rcc=feat[:, 46].cpu()\n",
    "    unique, counts = np.unique(rcc, return_counts=True)\n",
    "    coun = dict(zip(unique, counts))\n",
    "    rec_c = coun[0.0]\n",
    "    receptor = feat[:rec_c, 3:]\n",
    "    ligand = feat[rec_c:, 3:]\n",
    "    coord=feat[:,:3]\n",
    "    if receptor.shape[0]>999 or receptor.shape[0]<75 or ligand.shape[0]>999 or ligand.shape[0]<75:\n",
    "        continue\n",
    "#     receptor = receptor.expand(receptor.shape[0], receptor.shape[0],receptor.shape[1]).permute(2,1,0)\n",
    "#     ligand = ligand.expand(ligand.shape[0], ligand.shape[0],ligand.shape[1]).permute(2,1,0)\n",
    "#     print(i,ligand.shape)\n",
    "    len_rec.append(rec_c)\n",
    "    input_edges_rec.append(adjr)\n",
    "    input_edges_lig.append(adjl)\n",
    "    edge_index_rec.append(adjr.nonzero().t().contiguous())\n",
    "    edge_index_lig.append(adjl.nonzero().t().contiguous())\n",
    "    for coor in coord:\n",
    "        coor[0]=sigm(coor[0])\n",
    "        coor[1]=sigm(coor[1])\n",
    "        coor[2]=sigm(coor[2])\n",
    "\n",
    "    x1,x2,x3 = torch.from_numpy(np.random.uniform(3.14/12, 3.14, 3))\n",
    "    cos1=torch.cos(x1)\n",
    "    cos2=torch.cos(x2)\n",
    "    cos3=torch.cos(x3)\n",
    "    sin1=torch.sin(x1)\n",
    "    sin2=torch.sin(x2)\n",
    "    sin3=torch.sin(x3)\n",
    "    RMatrix=torch.tensor([[cos1*cos2*cos3-sin1*sin3,cos3*cos2*sin1+sin3+cos1,-cos3*sin2 ],\\\n",
    "                            [-sin3*cos2*cos1-cos3*sin1, -sin3*cos2*sin1+cos3*cos1, sin3*sin2],\\\n",
    "                            [sin2*cos1,sin2*sin1,cos2]])\n",
    "\n",
    "    ligcoord=  ((RMatrix @ torch.tensor(coord[rec_c:,]).double().T)).T\n",
    "    reccoord=coord[:rec_c,:]\n",
    "\n",
    "    coord=torch.cat((ligcoord,reccoord),0)\n",
    "    feat = feat[:,3:]\n",
    "    xyzl.append(feat)\n",
    "    coord_all.append(coord)\n",
    "    sample_filel.append(i)#fullsamples.index(i))\n",
    "#     input_edges_rec.append(edgesrec)\n",
    "#     input_edges_lig.append(edgeslig)\n",
    "    xyz_outl.append(torch.load(os.path.join('/workspace/EpipredFeat', fullsamples[i]+'_interface.pt')))\n",
    "    sample_file.append((fullsamples[i]+'1',fullsamples[i]+'2'))\n",
    "\n",
    "    #     break\n",
    "    \n",
    "len(xyzl), len(xyz_outl), len(len_rec)#, len(input_edges_lig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb94be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataobjl = ProteinDataL( xyzl,  xyz_outl, len_rec,input_edges_lig,input_edges_rec,coord_all,edge_index_rec,edge_index_lig,0)#.to(device)  #edge_list, input_edges_rec, input_edges_lig,\n",
    "dataobjl.setup()\n",
    "trainer=Trainer(gpus=[1],max_epochs=3)\n",
    "modelpres=LinkPred().load_from_checkpoint('kfoldboii_trial1.ckpt')\n",
    "trainer.fit(modelpres,dataobjl)\n",
    "trainer.test(modelpres,dataobjl)\n",
    "trainer.save_checkpoint(\"kfoldboii_trial1_epi.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e70002",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataobjl = ProteinDataL( xyzl,  xyz_outl, len_rec,input_edges_lig,input_edges_rec,coord_all,edge_index_rec,edge_index_lig,1)#.to(device)  #edge_list, input_edges_rec, input_edges_lig,\n",
    "dataobjl.setup()\n",
    "trainer=Trainer(gpus=[1],max_epochs=3)\n",
    "modelpres=LinkPred().load_from_checkpoint('kfoldboii_trial1_epi.ckpt')\n",
    "trainer.fit(modelpres,dataobjl)\n",
    "trainer.test(modelpres,dataobjl)\n",
    "trainer.save_checkpoint(\"kfoldboii_trial1_epi.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de43410",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataobjl = ProteinDataL( xyzl,  xyz_outl, len_rec,input_edges_lig,input_edges_rec,coord_all,edge_index_rec,edge_index_lig,2)#.to(device)  #edge_list, input_edges_rec, input_edges_lig,\n",
    "dataobjl.setup()\n",
    "trainer=Trainer(gpus=[1],max_epochs=3)\n",
    "modelpres=LinkPred().load_from_checkpoint('kfoldboii_trial1_epi.ckpt')\n",
    "trainer.fit(modelpres,dataobjl)\n",
    "trainer.test(modelpres,dataobjl)\n",
    "trainer.save_checkpoint(\"kfoldboii_trial1_epi.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fd649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataobjl = ProteinDataL( xyzl,  xyz_outl, len_rec,input_edges_lig,input_edges_rec,coord_all,edge_index_rec,edge_index_lig,3)#.to(device)  #edge_list, input_edges_rec, input_edges_lig,\n",
    "dataobjl.setup()\n",
    "trainer=Trainer(gpus=[1],max_epochs=3)\n",
    "modelpres=LinkPred().load_from_checkpoint('kfoldboii_trial1_epi.ckpt')\n",
    "trainer.fit(modelpres,dataobjl)\n",
    "trainer.test(modelpres,dataobjl)\n",
    "trainer.save_checkpoint(\"kfoldboii_trial1_epi.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataobjl = ProteinDataL( xyzl,  xyz_outl, len_rec,input_edges_lig,input_edges_rec,coord_all,edge_index_rec,edge_index_lig,4)#.to(device)  #edge_list, input_edges_rec, input_edges_lig,\n",
    "dataobjl.setup()\n",
    "trainer=Trainer(gpus=[1],max_epochs=3)\n",
    "modelpres=LinkPred().load_from_checkpoint('kfoldboii_trial1_epi.ckpt')\n",
    "trainer.fit(modelpres,dataobjl)\n",
    "trainer.test(modelpres,dataobjl)\n",
    "trainer.save_checkpoint(\"kfoldboii_trial1_epi.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eaa7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataL(pl.LightningDataModule):\n",
    "    def __init__(self, node,  xyz_out, len_rec,input_edges_lig,input_edges_rec,coord,edge_index_rec,edge_index_lig,fold): #rec_edge, lig_edge,\n",
    "        super().__init__()\n",
    "        self.node = node\n",
    "        self.xyz_out = xyz_out\n",
    "        self.rec_edge = input_edges_rec\n",
    "        self.lig_edge = input_edges_lig\n",
    "        self.len_rec = len_rec\n",
    "        self.coord   =coord\n",
    "        self.edge_index_rec=edge_index_rec\n",
    "        self.edge_index_lig=edge_index_lig\n",
    "        self.fold=fold\n",
    "        self.setup()\n",
    "        \n",
    "    def setup(self, stage = None):\n",
    "        counto=0\n",
    "        together=[]\n",
    "        self.data= []\n",
    "        train_set=[]\n",
    "        test_set=[]\n",
    "        for i in range(len(self.node)):\n",
    "            self.data.append([\n",
    "                              self.node[i].float().clone().detach(),\n",
    "                              self.xyz_out[i].float().clone().detach(),\n",
    "                              self.coord[i].float().clone().detach(),\n",
    "                              self.lig_edge[i].float().clone().detach(),\n",
    "                              self.rec_edge[i].float().clone().detach(),\n",
    "                              self.edge_index_lig[i].float().clone().detach(),\n",
    "                              self.edge_index_rec[i].float().clone().detach(),\n",
    "                              self.len_rec[i]])\n",
    "        \n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=230696)    \n",
    "        for tog in kf.split(self.data):\n",
    "            together=together+[tog]\n",
    "        ti,vi=together[self.fold]\n",
    "        self.tii, self.vii = ti.tolist(), vi.tolist()\n",
    "        for i in self.vii:\n",
    "            test_set.append(self.data[i])\n",
    "        for i in self.tii:\n",
    "            train_set.append(self.data[i])\n",
    "\n",
    "\n",
    "        self.train_set,self.val_set=train_set,test_set\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=1,num_workers=32)\n",
    "\n",
    "#     def val_dataloader(self):\n",
    "#         return DataLoader(self.val_set, batch_size=1,num_workers=32)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=1,num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c923c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataobjl = ProteinDataL( xyzl,  xyz_outl, len_rec,input_edges_lig,input_edges_rec,coord_all,edge_index_rec,edge_index_lig,4)#.to(device)  #edge_list, input_edges_rec, input_edges_lig,\n",
    "dataobjl.setup()\n",
    "trainer.test(modelpres,dataobjl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e33f93d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
